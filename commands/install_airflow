#!/usr/bin/env bash

#
# install_airflow
#
# Install Airflow, with all Airflow packages

# Set up a virtualenv for Airflow
cd /opt/virtualenvs
virtualenv airflow

# Install libffi-dev
# (required for Airflow's crypto package)
sudo rpm -i http://195.220.108.108/linux/centos/7.3.1611/os/x86_64/Packages/libffi-devel-3.0.13-18.el7.x86_64.rpm
sudo yum -y install libffi-devel

# Make Airflow's home directory
mkdir /opt/airflow
echo export AIRFLOW_HOME=/opt/airflow >> /home/centos/.bash_profile
source /home/centos/.bash_profile

# Preempt the boilerplate Airflow configuraiton file with our own
cat << EOF | sudo tee /opt/airflow/airflow.cfg
[core]
airflow_home = /opt/airflow
dags_folder = /opt/airflow/dags
base_log_folder = /opt/airflow/logs
executor = SequentialExecutor
sql_alchemy_conn = sqlite:////opt/airflow/airflow.db
parallelism = 32
dag_concurrency = 16
load_examples = False
plugins_folder = /opt/airflow/plugins
fernet_key = `cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1`
unit_test_mode = False

[cli]
api_client = airflow.api.client.local_client
endpoint_url = http://localhost:8080

[api]
auth_backend = airflow.api.auth.backend.default

[operators]
default_owner = Airflow
default_cpus = 1
default_ram = 512
default_disk = 512
default_gpus = 0

[webserver]
base_url = http://localhost:8080
web_server_host = 0.0.0.0
web_server_port = 8080
worker_refresh_batch_size = 1
worker_refresh_interval = 30
secret_key = `cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1`
workers = 4
worker_class = sync

[scheduler]
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 5
run_duration = -1
min_file_process_interval = 0
dag_dir_list_interval = 300
print_stats_interval = 30
child_process_log_directory = /opt/airflow/logs/scheduler
scheduler_zombie_task_threshold = 300
catchup_by_default = True
max_threads = 2
authenticate = False

[github_enterprise]
api_rev = v3
EOF
sudo chown centos:centos /opt/airflow/airflow.cfg

# Install Airflow, with all Airflow packages
cd /opt/airflow
/opt/virtualenvs/airflow/bin/pip install airflow[all]

# Initialize the Airflow database
/opt/virtualenvs/airflow/bin/airflow initdb

# Add Airflow's binary directory to the $PATH, so that Airflow can find the binaries it depends on, like gunicorn
echo PATH=\$PATH:/opt/virtualenvs/airflow/bin >> ~/.bash_profile
source /home/centos/.bash_profile

# Make a script that can start Airflow with all environmental variables
# (Perfect for use in non-interactive shells without Virtualenv's activate)
cat << EOF | sudo tee /opt/airflow/start_airflow
#!/usr/bin/env bash

VIRTUAL_ENV="/opt/virtualenvs/airflow" PATH="\$VIRTUAL_ENV/bin:\$PATH" AIRFLOW_HOME=/opt/airflow /opt/virtualenvs/airflow/bin/airflow webserver -p 8080

EOF
sudo chown centos:centos /opt/airflow/start_airflow
chmod +x /opt/airflow/start_airflow

# N.B., this is how you start the Airflow web server as a logged-in user
# /opt/virtualenvs/airflow/bin/airflow webserver -p 8080
